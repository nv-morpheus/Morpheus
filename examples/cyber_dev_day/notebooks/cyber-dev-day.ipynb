{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2941e94f-db20-44a5-ab87-2cab499825f7",
   "metadata": {},
   "source": [
    "# Cyber Developer Day 2024\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Generative AI (GenAI) and Large Language Models (LLMs) are becoming essential tools in cybersecurity in part due to their ability to enhance the efficiency of cyber threat detection and response by accelerating analyst workflows.\n",
    "\n",
    "### Problem Statement:\n",
    "Determining the impact of a documented Common Vulnerabilities and Exposures (CVE) on a specific project or container is a labor-intensive and manual task. This process involves the collection, comprehension, and synthesis of various pieces of information to ascertain whether immediate remediation, such as patching, is necessary upon the identification of a new CVE. Often, reasons cited for not updating a library affected by a CVE include the occurrence of scan false positives, the existence of mitigating factors, or the absence of necessary environments or dependencies for the exploit to be viable. Once an analyst has determined the library is not affected, a Vulnerability Exploitability eXchange (VEX) document must be created to standardize and distribute the results. The efficiency of this process can be significantly enhanced through the deployment of an event-driven LLM agent pipeline.\n",
    "\n",
    "### Tutorial Goals:\n",
    "Our team developed a cybersecurity vulnerability analysis tool to aid in assessing the exploitability of CVEs in specific projects and containers. The following tutorial shows step-by-step how to leverage LLMs, RAG, and agents to create toy version and microservice running LLM-powered CVE exploitability analysis.\n",
    "Students can experiment with the different modules to expand on this use case or leverage these modular pieces to construct a new pipeline of their own.\n",
    "\n",
    "### Outline\n",
    "#### Part 1 - Intro to Interacting with LLMs\n",
    "    a. Python calls to LLM API\n",
    "    b. Prompt engineering\n",
    "    c. Prompt templating\n",
    "    d. One-shot learning\n",
    "    e. Multi-shot learning\n",
    "    f. Fine-tuning LLMs\n",
    "    \n",
    "#### Part 2 - Prototyping\n",
    "    a. Building a Vector Database\n",
    "    b. Running a RAG pipeline with Morpheus\n",
    "    c. Running the CVE Pipeline with Morpheus\n",
    "    \n",
    "#### Part 3 - Beyond Prototyping\n",
    "    a. Improving the Model\n",
    "    b. Batching Requests\n",
    "    c. Creating a Microservice\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Please continue running the notebook up to Part 1 during the introduction presentation to ensure your environment is set up correctly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700a3a1",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "The following code blocks are used to setup environment variables and imports for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d2a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport -logging\n",
    "%autoreload 2\n",
    "\n",
    "# Ensure that the morpheus directory is in the python path. This may not need to be run depending on the environment setup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if (\"MORPHEUS_ROOT\" not in os.environ):\n",
    "    os.environ[\"MORPHEUS_ROOT\"] = os.path.abspath(\"../../..\")\n",
    "\n",
    "llm_dir = os.path.abspath(os.path.join(os.getenv(\"MORPHEUS_ROOT\", \"../../..\"), \"examples\", \"cyber_dev_day\"))\n",
    "\n",
    "if (llm_dir not in sys.path):\n",
    "    sys.path.append(llm_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523bc32",
   "metadata": {},
   "source": [
    "Ensure the necessary environment variables are set. As a last resort, try to load them from a `.env` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef295094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure that the current environment is set up with API keys\n",
    "required_env_vars = [\n",
    "    \"MORPHEUS_ROOT\",\n",
    "    \"NGC_API_KEY\",\n",
    "    \"NVIDIA_API_KEY\",\n",
    "]\n",
    "\n",
    "if (not all([var in os.environ for var in required_env_vars])):\n",
    "\n",
    "    # Try loading an .env file if it exists\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    # Check again\n",
    "    if (not all([var in os.environ for var in required_env_vars])):\n",
    "        raise ValueError(f\"Please set the following environment variables: {required_env_vars}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa2691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global imports\n",
    "import os\n",
    "import sys\n",
    "import cudf\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932f728",
   "metadata": {},
   "source": [
    "Configure logging to allow Morpheus messages to appear in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab76ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "import logging\n",
    "import cyber_dev_day\n",
    "\n",
    "# Create a logger for this module. Use the cyber_dev_day module name because the notebook will just be __main__\n",
    "logger = logging.getLogger(cyber_dev_day.__name__)\n",
    "\n",
    "# Configure the root logger log level\n",
    "logger.root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a1fcfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the logger out. You should see the log message in the output\n",
    "logger.info(\"Successfully configured logging!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb62b83",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Please wait here until instructed to continue with running Part 1 of the notebook.\n",
    "</div>\n",
    "\n",
    "## Part 1 - Intro to Interacting with LLMs\n",
    "\n",
    "This section will go over how to integrate LLMs into code with Python based examples.\n",
    "\n",
    "We will cover-\n",
    "\n",
    "    a. Python calls to LLM API\n",
    "    b. Prompt engineering\n",
    "    c. Prompt templating\n",
    "    d. One-shot learning\n",
    "    e. Multi-shot learning\n",
    "    f. Fine-tuning LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8634848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nemollm.api import NemoLLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639ba36-02ac-4a94-9815-182bbda12c38",
   "metadata": {},
   "source": [
    "### Part 1a - single call to LLM API\n",
    "#### Use case - general cyber knowledge assistant, productivity tool to aid cyber analysts\n",
    "\n",
    "`Query: How can you determine if a CVE is vulnerable in your specific environment?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff3a3b9-911c-45f0-b46a-6ac2a1c0a621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conn = NemoLLM(api_key=os.getenv(\"NGC_API_KEY\"), org_id=os.getenv(\"NGC_ORG_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e8a57-d198-4f6b-911b-0500f97a983d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = conn.generate(\n",
    "  prompt=\"In general, how can I determine if my specific environment is affected by a CVE?\",\n",
    "  model=\"gpt-43b-002\",\n",
    "  stop=[],\n",
    "  tokens_to_generate=128,\n",
    "  temperature=0,\n",
    "  top_k=1,\n",
    "  top_p=0.9,\n",
    "  random_seed=0,\n",
    "  beam_search_diversity_rate=0.0,\n",
    "  beam_width=1,\n",
    "  repetition_penalty=1.0,\n",
    "  length_penalty=1.0,\n",
    ")\n",
    "response[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d4222-9f6d-46cf-b037-b765889825cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### *Explore on your own*\n",
    "\n",
    "#### Try another model such as `gpt-8b-000` `gpt20b` or `llama2-70b-HF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef49a4-df05-4f68-8cd8-7eb053e31397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = conn.generate(\n",
    "  prompt=\"In general, how can I determine if my specific environment is affected by a CVE?\",\n",
    "  model=\"gpt-8b-000\",\n",
    "  stop=[],\n",
    "  tokens_to_generate=128,\n",
    "  temperature=0,\n",
    "  top_k=1,\n",
    "  top_p=0.9,\n",
    "  random_seed=0,\n",
    "  beam_search_diversity_rate=0.0,\n",
    "  beam_width=1,\n",
    "  repetition_penalty=1.0,\n",
    "  length_penalty=1.0\n",
    ")\n",
    "response[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffff783-1e41-46cb-a819-e9fb96252d31",
   "metadata": {},
   "source": [
    "### *Explore on your own*\n",
    "##### How do the different models compare? Can you change the parameters (like `temperature` or `repetition_penalty`) to help the smaller models improve?\n",
    "##### What are some other cybersecurity questions you could ask an LLM to upskill a junior analyst?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03af5d2-0931-4e0c-a27a-d280c9f77fcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 1b - prompt engineering using personas\n",
    "\n",
    "Some tips for improving performance using prompt engineering can be found here https://www.promptingguide.ai/introduction/tips\n",
    "\n",
    "\n",
    "`Persona: You are a helpful cybersecurity analyst with an IQ of 140.`\n",
    "\n",
    "`Query: In general, how can I determine if my specific environment is vulnerable to a CVE?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95010654-9f3e-4cb1-bb31-d4ceb288c9da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"{persona} {query}\"\n",
    "\n",
    "formatted_prompt = prompt_template.format(persona=\"You are helpful cybersecurity expert with an IQ of 140.\",\n",
    "                                          query=\"In general, how can I determine if my specific environment is vulnerable to a CVE?\")\n",
    "\n",
    "\n",
    "response = conn.generate(\n",
    "  prompt= formatted_prompt,\n",
    "  model=\"gpt-43b-002\",\n",
    "  stop=[],\n",
    "  tokens_to_generate=256,\n",
    "  temperature=0,\n",
    "  top_k=1,\n",
    "  top_p=0.9,\n",
    "  random_seed=0,\n",
    "  beam_search_diversity_rate=0.0,\n",
    "  beam_width=1,\n",
    "  repetition_penalty=1.0,\n",
    "  length_penalty=1.0\n",
    ");\n",
    "\n",
    "response[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1035ba69-8a51-4d92-950f-d1b4e420cd70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### *Explore on your own*\n",
    "##### Does the persona improve performance?\n",
    "##### What happens if you change the persona or attributes such as IQ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265febf-5117-4010-a879-dc41ab957c5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 1c - prompt template to include specific CVE context for the model\n",
    "\n",
    "Can our LLM help with specific CVEs?\n",
    "\n",
    "`Query: \"How can I determine if my specific environment is affected by CVE-2023-47248?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8923b1fa-1a41-4fb6-83f3-dacca4bc9316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"{persona} {query}\"\n",
    "\n",
    "formatted_prompt = prompt_template.format(persona=\"You are helpful cybersecurity expert with an IQ of 140.\",\n",
    "                                          query=\"How can I determine if my specific environment is affected by CVE-2023-47248?\")\n",
    "\n",
    "\n",
    "response = conn.generate(\n",
    "  prompt= formatted_prompt,\n",
    "  model=\"gpt-43b-002\",\n",
    "  stop=[],\n",
    "  tokens_to_generate=256,\n",
    "  temperature=0,\n",
    "  top_k=1,\n",
    "  top_p=0.9,\n",
    "  random_seed=0,\n",
    "  beam_search_diversity_rate=0.0,\n",
    "  beam_width=1,\n",
    "  repetition_penalty=1.0,\n",
    "  length_penalty=1.0\n",
    ");\n",
    "\n",
    "response[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f374c4a4-67b1-4dad-92c8-ca74995af35c",
   "metadata": {},
   "source": [
    "##### What are some methods to get up-to-date CVE knowledge to our model?\n",
    "\n",
    "##### Can we add it to the prompt?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6dcba4-4e4b-4dd4-8c46-5eb7f767385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"Generate a checklist for a security analyst to use when assessing the exploitability of a specific CVE within a containerized environment. \\\n",
    "For each checklist item, start with an action verb, making it clear and actionable. Provide the checklist as a Python list of strings. \\\n",
    "Utilize the provided CVE details below to tailor the checklist items specifically for this CVE. \\\n",
    "CVE Details: \\\n",
    "- CVE ID: {cve} \\\n",
    "- Description: {cve_description} \\\n",
    "- Vulnerable Package Name: {vuln_package} \\\n",
    "- CVSS3 Vector String: {cvss3}\"\n",
    "\n",
    "formatted_prompt = prompt_template.format(cve = \"2023-47248\",\n",
    "                                          cve_description= \"Deserialization of untrusted data in IPC and Parquet readers in PyArrow versions 0.14.0 to 14.0.0 \\\n",
    "                                          allows arbitrary code execution. An application is vulnerable if it reads Arrow IPC, Feather or Parquet data from untrusted sources \\\n",
    "                                          (for example user-supplied input files). This vulnerability only affects PyArrow, not other Apache Arrow implementations or bindings. \\\n",
    "                                          It is recommended that users of PyArrow upgrade to 14.0.1. Similarly, it is recommended that downstream libraries upgrade their dependency \\\n",
    "                                          requirements to PyArrow 14.0.1 or later. PyPI packages are already available, and we hope that conda-forge packages will be available soon. \\\n",
    "                                          If it is not possible to upgrade, we provide a separate package `pyarrow-hotfix` that disables the vulnerability on older PyArrow versions. \\\n",
    "                                          See https://pypi.org/project/pyarrow-hotfix/ for instructions.\",\n",
    "                                          vuln_package=\"PyArrow\",\n",
    "                                          cvss3=\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\")\n",
    "\n",
    "response = conn.generate(\n",
    "  prompt= formatted_prompt,\n",
    "  model=\"gpt-43b-002\",\n",
    "  stop=[],\n",
    "  tokens_to_generate=128,\n",
    "  temperature=0,\n",
    "  top_k=1,\n",
    "  top_p=0.9,\n",
    "  random_seed=0,\n",
    "  beam_search_diversity_rate=0.0,\n",
    "  beam_width=1,\n",
    "  repetition_penalty=1.0,\n",
    "  length_penalty=1.0\n",
    ");\n",
    "\n",
    "response[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6224e8-a506-406b-8d16-e9300f158fdb",
   "metadata": {},
   "source": [
    "##### Is this a useful planning step and thought process?\n",
    "\n",
    "##### Did the model generate the checklist/task list as a python list of strings as we requested?\n",
    "\n",
    "##### How can we measure accuracy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb9fc6-2137-4b93-9fdd-80b9759549c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can evaulate if the checklist is properly formatted using this function\n",
    "\n",
    "def is_properly_formatted_list(checklist):\n",
    "    try:\n",
    "        # Attempt to evaluate checklist as a Python literal\n",
    "        evaluated_checklist = ast.literal_eval(checklist)\n",
    "        \n",
    "        # Check if the evaluated object is a list\n",
    "        if isinstance(evaluated_checklist, list):\n",
    "            print(\"Checklist is properly formatted.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Checklist is not a list.\")\n",
    "            return False\n",
    "    except ValueError as e:\n",
    "        # Handle the case where checklist cannot be evaluated as a Python literal\n",
    "        print(f\"Checklist is not properly formatted: {e}\")\n",
    "        return False\n",
    "    except SyntaxError as e:\n",
    "        # Handle syntax errors in the checklist string\n",
    "        print(f\"Checklist has a syntax error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f10a1-f446-4987-a1d1-7daf69c46a84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_properly_formatted_list(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b10cf-994e-4ed8-8414-86ecd820708d",
   "metadata": {},
   "source": [
    "How can we improve performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e48eb-073f-4984-a398-9b5f118391a2",
   "metadata": {},
   "source": [
    "### Part 1d - including an example in the prompt (one-shot learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49717a-6e08-44dd-b87d-cb26091a64fd",
   "metadata": {},
   "source": [
    "You are an expert secuirty analyst. Your objective is to add a \"Checklist\" section containing steps to use when assessing the exploitability of a specific CVE within a containerized environment. \\\n",
    "For each checklist item, start with an action verb, making it clear and actionable\n",
    "\n",
    "**Context**:\n",
    "Not all CVEs are exploitable in a given container. By making a checklist specific to the information available for a given CVE analysts can execute the checklist to determine exploitability.\n",
    "\n",
    "**Example Format**:\n",
    "Below is a format for examples that illustrate transforming CVE information into an exploitability assessment checklist.\n",
    "\n",
    "Example CVE Details:\n",
    "- CVE ID: CVE-2022-2309 \\\n",
    "- Description: NULL Pointer Dereference allows attackers to cause a denial of service (or application crash). This only applies when lxml up to version 4.9.1 \\\n",
    "is used together with libxml2 2.9.10 through 2.9.14. libxml2 2.9.9 and earlier are not affected. It allows triggering crashes through forged input data, given a\n",
    "vulnerable code sequence in the application. The vulnerability is caused by the iterwalk function (also used by the canonicalize function). Such code shouldn't be\n",
    "in wide-spread use, given that parsing + iterwalk would usually be replaced with the more efficient iterparse function. However, an XML converter that serialises to \\\n",
    "C14N would also be vulnerable, for example, and there are legitimate use cases for this code sequence. If untrusted input is received (also remotely) and processed via \\\n",
    "iterwalk function, a crash can be triggered. \n",
    "- Vulnerable Package Name: lxml, libxml2 \n",
    "- Vulnerable Package Version: lxml: up to 4.9.1, libxml2: 2.91.0 through 2.9.14\n",
    "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H\n",
    "\n",
    "Example Exploitability Assessment Checklist: \\\n",
    "[\n",
    "\"Check for lxml: Verify if your project uses the lxml library, which is the affected package. If lxml is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
    "\"Review Affected Versions: If lxml is used, checked the version that your project depends on. According to the vulnerability details, versions 4.9.0 and earlier are vulnerable.\",\n",
    "\"Review Versions of Connected Dependencies: The package is only vulnerable if libxml 2.9.10 through 2.9.14 is also present. Check the version of libxml in the project.\",\n",
    "\"Check for use of vulnerable functions: The library is vulnerable through its `iterwalk` function, which is also utilized by the `canonicalize` function. Check if either of these functions are used in your code base.\"\n",
    "]\n",
    "\n",
    "**Criteria**:\n",
    "- Exploitability assessment checklists must relate to the information in the specific CVE Details.\n",
    "\n",
    "**Procedure**:\n",
    "[\n",
    "\"Understand the CVE Details, description, and CVSS3 attack vector string.\",\n",
    "\"Produce a CVE exploitability assessment checklist.\",\n",
    "\"Format the checklist as comma separated list surrounded by square braces.\",\n",
    "\"Output the checklist.\"\n",
    "]\n",
    "\n",
    "**CVE Details:**\n",
    "- CVE ID: {cve} \\\n",
    "- Description: {cve_description} \\\n",
    "- Vulnerable Package Name: {vuln_package} \\\n",
    "- CVSS3 Vector String: {cvss3}\"\n",
    "\n",
    "**Checklist**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665023f4-f5a1-45cc-aeb4-e59dac16c1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are an expert secuirty analyst. Your objective is to add a \"Checklist\" section containing steps to use when assessing the exploitability of a specific CVE within a containerized environment. \\\n",
    "For each checklist item, start with an action verb, making it clear and actionable\n",
    "\n",
    "**Context**:\n",
    "Not all CVEs are exploitable in a given container. By making a checklist specific to the information available for a given CVE analysts can execute the checklist to determine exploitability.\n",
    "\n",
    "**Example Format**:\n",
    "Below is a format for examples that illustrate transforming CVE information into an exploitability assessment checklist.\n",
    "\n",
    "Example CVE Details:\n",
    "- CVE ID: CVE-2022-2309 \\\n",
    "- Description: NULL Pointer Dereference allows attackers to cause a denial of service (or application crash). This only applies when lxml up to version 4.9.1 \\\n",
    "is used together with libxml2 2.9.10 through 2.9.14. libxml2 2.9.9 and earlier are not affected. It allows triggering crashes through forged input data, given a\n",
    "vulnerable code sequence in the application. The vulnerability is caused by the iterwalk function (also used by the canonicalize function). Such code shouldn't be\n",
    "in wide-spread use, given that parsing + iterwalk would usually be replaced with the more efficient iterparse function. However, an XML converter that serialises to \\\n",
    "C14N would also be vulnerable, for example, and there are legitimate use cases for this code sequence. If untrusted input is received (also remotely) and processed via \\\n",
    "iterwalk function, a crash can be triggered. \n",
    "- Vulnerable Package Name: lxml, libxml2 \n",
    "- Vulnerable Package Version: lxml: up to 4.9.1, libxml2: 2.91.0 through 2.9.14\n",
    "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H\n",
    "\n",
    "Example Exploitability Assessment Checklist: \\\n",
    "[\n",
    "\"Check for lxml: Verify if your project uses the lxml library, which is the affected package. If lxml is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
    "\"Review Affected Versions: If lxml is used, checked the version that your project depends on. According to the vulnerability details, versions 4.9.0 and earlier are vulnerable.\",\n",
    "\"Review Versions of Connected Dependencies: The package is only vulnerable if libxml 2.9.10 through 2.9.14 is also present. Check the version of libxml in the project.\",\n",
    "\"Check for use of vulnerable functions: The library is vulnerable through its `iterwalk` function, which is also utilized by the `canonicalize` function. Check if either of these functions are used in your code base.\"\n",
    "]\n",
    "\n",
    "**Criteria**:\n",
    "- Exploitability assessment checklists must relate to the information in the specific CVE Details.\n",
    "\n",
    "**Procedure**:\n",
    "[\n",
    "\"Understand the CVE Details, description, and CVSS3 attack vector string.\",\n",
    "\"Produce a CVE exploitability assessment checklist.\",\n",
    "\"Format the checklist as comma separated list surrounded by square braces.\",\n",
    "\"Output the checklist.\"\n",
    "]\n",
    "\n",
    "**CVE Details:**\n",
    "- CVE ID: {cve}\n",
    "- Description: {cve_description}\n",
    "- Vulnerable Package Name: {vuln_package}\n",
    "- CVSS3 Vector String: {cvss3}\"\n",
    "\n",
    "**Checklist**: \"\"\"\n",
    "\n",
    "formatted_prompt = prompt_template.format(cve = \"2023-47248\",\n",
    "                                          cve_description= \"Deserialization of untrusted data in IPC and Parquet readers in PyArrow versions 0.14.0 to 14.0.0 \\\n",
    "                                          allows arbitrary code execution. An application is vulnerable if it reads Arrow IPC, Feather or Parquet data from untrusted sources \\\n",
    "                                          (for example user-supplied input files). This vulnerability only affects PyArrow, not other Apache Arrow implementations or bindings. \\\n",
    "                                          It is recommended that users of PyArrow upgrade to 14.0.1. Similarly, it is recommended that downstream libraries upgrade their dependency \\\n",
    "                                          requirements to PyArrow 14.0.1 or later. PyPI packages are already available, and we hope that conda-forge packages will be available soon. \\\n",
    "                                          If it is not possible to upgrade, we provide a separate package `pyarrow-hotfix` that disables the vulnerability on older PyArrow versions. \\\n",
    "                                          See https://pypi.org/project/pyarrow-hotfix/ for instructions.\",\n",
    "                                          vuln_package=\"PyArrow\",\n",
    "                                          cvss3=\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\")\n",
    "\n",
    "response = conn.generate(\n",
    "  prompt= formatted_prompt,\n",
    "  model=\"gpt-43b-002\",\n",
    "  stop=[],\n",
    "  tokens_to_generate=256,\n",
    "  temperature=0,\n",
    "  top_k=1,\n",
    "  top_p=0.9,\n",
    "  random_seed=0,\n",
    "  beam_search_diversity_rate=0.0,\n",
    "  beam_width=1,\n",
    "  repetition_penalty=1.0,\n",
    "  length_penalty=1.0\n",
    ");\n",
    "\n",
    "response[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f42e7-10ac-46b5-8df6-5f3d1f6d19a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_properly_formatted_list(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab5e62-b82e-4add-aea2-8ae58aba4c28",
   "metadata": {},
   "source": [
    "##### Do the examples and specific instructions help?\n",
    "\n",
    "##### Is there anything you would add to the PyArrow checklist?\n",
    "\n",
    "##### Would an example with a workaround or hotfix help?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08bba90-3201-4c95-b8c4-6f4d2eb0f3a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 1e- including multiple examples in the prompt (few-shot learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62834ec0-ef09-4462-88e1-851066dd45cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are an expert secuirty analyst. Your objective is to add a \"Checklist\" section containing steps to use when assessing the exploitability of a specific CVE within a containerized environment. \\\n",
    "For each checklist item, start with an action verb, making it clear and actionable\n",
    "\n",
    "**Context**:\n",
    "Not all CVEs are exploitable in a given container. By making a checklist specific to the information available for a given CVE analysts can execute the checklist to determine exploitability.\n",
    "\n",
    "**Example Format**:\n",
    "Below is a format for examples that illustrate transforming CVE information into an exploitability assessment checklist.\n",
    "\n",
    "Example 1 CVE Details:\n",
    "- CVE ID: CVE-2022-2309\n",
    "- Description: NULL Pointer Dereference allows attackers to cause a denial of service (or application crash). This only applies when lxml up to version 4.9.1 \\\n",
    "is used together with libxml2 2.9.10 through 2.9.14. libxml2 2.9.9 and earlier are not affected. It allows triggering crashes through forged input data, given a\n",
    "vulnerable code sequence in the application. The vulnerability is caused by the iterwalk function (also used by the canonicalize function). Such code shouldn't be\n",
    "in wide-spread use, given that parsing + iterwalk would usually be replaced with the more efficient iterparse function. However, an XML converter that serialises to \\\n",
    "C14N would also be vulnerable, for example, and there are legitimate use cases for this code sequence. If untrusted input is received (also remotely) and processed via \\\n",
    "iterwalk function, a crash can be triggered. \n",
    "- Vulnerable Package Name: lxml, libxml2 \n",
    "- Vulnerable Package Version: lxml: up to 4.9.1, libxml2: 2.91.0 through 2.9.14\n",
    "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H\n",
    "\n",
    "Example 1 Exploitability Assessment Checklist:\n",
    "[\n",
    "\"Check for lxml: Verify if your project uses the lxml library, which is the affected package. If lxml is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
    "\"Review Affected Versions: If lxml is used, checked the version that your project depends on. According to the vulnerability details, versions 4.9.0 and earlier are vulnerable.\",\n",
    "\"Review Versions of Connected Dependencies: The package is only vulnerable if libxml 2.9.10 through 2.9.14 is also present. Check the version of libxml in the project.\",\n",
    "\"Check for use of vulnerable functions: The library is vulnerable through its `iterwalk` function, which is also utilized by the `canonicalize` function. Check if either of these functions are used in your code base.\"\n",
    "]\n",
    "\n",
    "Example 2 CVE Details:\n",
    "- CVE ID: CVE-2024-23334\n",
    "- Description: aiohttp is an asynchronous HTTP client/server framework for asyncio and Python. When using aiohttp as a web server and configuring static routes, \\\n",
    "it is necessary to specify the root path for static files. Additionally, the option 'follow_symlinks' can be used to determine whether to follow symbolic links \\\n",
    "outside the static root directory. When 'follow_symlinks' is set to True, there is no validation to check if reading a file is within the root directory. This can \\\n",
    "lead to directory traversal vulnerabilities, resulting in unauthorized access to arbitrary files on the system, even when symlinks are not present. \\\n",
    "Disabling `follow_symlinks` by setting `follow_symlinks = False` and using a reverse proxy are encouraged mitigations. Version 3.9.2 fixes this issue.\n",
    "- Vulnerable Package Name: aiohttp\n",
    "- Vulnerable Package Version: from 1.0.5 up to (excluding) 3.9.2\n",
    "- CVSS3 Vector String: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N\n",
    "\n",
    "Example 2 Exploitability Assessment Checklist:\n",
    "[\n",
    "    \"Check for aiohttp: Verify if your project uses the aiohttp library, which is the affected package. If aiohttp is not a dependency in your project, then your code is not vulnerable to this CVE.\",\n",
    "    \"Review Affected Versions: If aiohttp is used, check the version that your project depends on. According to the vulnerability details, versions from 1.0.5 up to (excluding) 3.9.2 are affected by this vulnerability.\",\n",
    "    \"Review Code To Check for Vulnerability Mitigation: Check if the 'follow_symlinks' option is set to False to mitigate the risk of directory traversal vulnerabilities.\"\n",
    "]\n",
    "\n",
    "**Criteria**:\n",
    "- Exploitability assessment checklists must relate to the information in the specific CVE Details.\n",
    "- Exploitability assessment checklists must include checks for mitigating conditions when present in the CVE Details.\n",
    "\n",
    "**Procedure**:\n",
    "[\n",
    "\"Understand the CVE Details, description, and CVSS3 attack vector string.\",\n",
    "\"Produce a CVE exploitability assessment checklist.\",\n",
    "\"Format the checklist as comma separated list surrounded by square braces.\",\n",
    "\"Output the checklist.\"\n",
    "]\n",
    "\n",
    "**CVE Details:**\n",
    "- CVE ID: {cve}\n",
    "- Description: {cve_description}\n",
    "- Vulnerable Package Name: {vuln_package}\n",
    "- CVSS3 Vector String: {cvss3}\"\n",
    "\n",
    "**Checklist**: \"\"\"\n",
    "\n",
    "\n",
    "formatted_prompt = prompt_template.format(cve = \"2023-47248\",\n",
    "                                          cve_description= \"Deserialization of untrusted data in IPC and Parquet readers in PyArrow versions 0.14.0 to 14.0.0 \\\n",
    "                                          allows arbitrary code execution. An application is vulnerable if it reads Arrow IPC, Feather or Parquet data from untrusted sources \\\n",
    "                                          (for example user-supplied input files). This vulnerability only affects PyArrow, not other Apache Arrow implementations or bindings. \\\n",
    "                                          It is recommended that users of PyArrow upgrade to 14.0.1. Similarly, it is recommended that downstream libraries upgrade their dependency \\\n",
    "                                          requirements to PyArrow 14.0.1 or later. PyPI packages are already available, and we hope that conda-forge packages will be available soon. \\\n",
    "                                          If it is not possible to upgrade, we provide a separate package `pyarrow-hotfix` that disables the vulnerability on older PyArrow versions. \\\n",
    "                                          See https://pypi.org/project/pyarrow-hotfix/ for instructions.\",\n",
    "                                          vuln_package=\"PyArrow\",\n",
    "                                          cvss3=\"CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H\")\n",
    "\n",
    "len(formatted_prompt)\n",
    "\n",
    "response = conn.generate(\n",
    "  prompt= formatted_prompt,\n",
    "  model=\"gpt-43b-002\",\n",
    "  stop=[],\n",
    "  tokens_to_generate=256,\n",
    "  temperature=0,\n",
    "  top_k=1,\n",
    "  top_p=0.9,\n",
    "  random_seed=0,\n",
    "  beam_search_diversity_rate=0.0,\n",
    "  beam_width=1,\n",
    "  repetition_penalty=1.0,\n",
    "  length_penalty=1.0\n",
    ");\n",
    "\n",
    "response[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a3924-eb83-4ce4-91d3-e9fb7f9648b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_properly_formatted_list(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d50410-fe09-4569-8aab-e72e4a808bc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### *Explore on your own*\n",
    "\n",
    "#### What happens when you input a tasklist item as query to the model?\n",
    "\n",
    "#### What are your concerns about the model output?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759fb88-5f15-40f6-a38b-8fd98ad88afa",
   "metadata": {},
   "source": [
    "### Part 1f - LORA fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb9a16-d3ec-4184-9031-1cf6822965a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "When you have more task-specific examples than space in your prompt you should consider fine-tuning and LLM for your specific task. Datasets required for fine-tuning have examples with just two fields- `Prompt` and `Completion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44073381-1b61-4820-b7e1-acbfcb1b9573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4e57e-d1ed-41c0-bdea-0f371fb87d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0afdc87a",
   "metadata": {},
   "source": [
    "## Part 2 - Prototyping\n",
    "\n",
    "Now that we have the task generation for this workflow ready, how can we automate getting the answers for our checklist items?\n",
    "\n",
    "### Overview\n",
    "\n",
    "It is possible to build a language model-based system that accesses external knowledge sources to complete tasks. In Part 1c above, we added additional CVE details into the prompt by hand. While this strategy can be effective for adding additional context for very specific items like CVE Details, it requires apriori knowledge of what details to include (like those from NVD). When you would like to help your LLM with its query by adding more context in real-time, you're ready for RAG (Retreival Augmented Generation). \n",
    "\n",
    "When a query or checklist item is posed to an LLM equipped with RAG, the model first consults the vector database to find relevant information related to the query. This retrieved data is then combined with the original question and fed back into the LLM. With this enriched context, the LLM can generate a more accurate and informed response, potentially including evidence or reasoning based on the newly incorporated data. This approach not only improves the quality of the LLM's outputs and for our tool gives it access to project and container specific information to determine CVE exploitability.\n",
    "\n",
    "### Building the Vector Database\n",
    "\n",
    "In addition to having a query and LLM, RAG requires additional information to be stored in a vector database. One mechanism of finding the proper information from the database is to first embed the query into the same vector space and retreive the top most similiar items via a distance metric. The additional information is then presented in the prompt of the LLM. The neighboring vectors in the database are said to be \"semanically similiar\" to the query and likely relevant.\n",
    "\n",
    "For our demonstration purposes, a we would like our LLM to be able to access include the code repository of the project we're interested in checking for exploitable CVEs. The first step is transforming the repo into a vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5175d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from cyber_dev_day.embeddings import create_code_embedding\n",
    "\n",
    "# Create the embedding object that will be used to generate the embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\", model_kwargs={\"device\":\"cuda\"}, show_progress=True)\n",
    "\n",
    "# Create a vector database of the code using the supplied embedding function. The returned value will be a\n",
    "# FaissVectorDatabase object.\n",
    "# NOTE: This may take a few minutes to run.\n",
    "faiss_vdb = create_code_embedding(code_dir=os.getenv(\"MORPHEUS_ROOT\"), embedding=embeddings, include_notebooks=False, exclude=[\n",
    "    \".cache/**/*.py\",\n",
    "    \"build*/**/*.py\"\n",
    "])\n",
    "\n",
    "# Save the vector database to disk\n",
    "code_faiss_dir = os.path.join(os.getenv(\"MORPHEUS_ROOT\"), \".tmp\", \"morpheus_code_faiss\")\n",
    "\n",
    "faiss_vdb.save_local(code_faiss_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0cd628",
   "metadata": {},
   "source": [
    "### Running a RAG Pipeline with Morpheus\n",
    "\n",
    "How do we utilize the Vector Database to answer questions?\n",
    "\n",
    "#### Morpheus Overview\n",
    "\n",
    "Quick overview of what Morpheus is and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9cbc52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from morpheus.config import Config, PipelineModes\n",
    "\n",
    "# Create the pipeline config\n",
    "pipeline_config = Config()\n",
    "pipeline_config.mode = PipelineModes.OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7829100",
   "metadata": {},
   "source": [
    "#### Building a Morpheus RAG Pipeline\n",
    "\n",
    "Below, we will build a pipeline that uses Morpheus to answer questions about the code in the repository that we created a vector database for. This works by using the `LLMEngine` in Morpheus with a `RAGNode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833deda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "import cudf\n",
    "from cyber_dev_day.config import EngineConfig, LLMModelConfig, NVFoundationLLMModelConfig\n",
    "from morpheus._lib.llm import LLMEngine\n",
    "from morpheus.llm.nodes.extracter_node import ExtracterNode\n",
    "from morpheus.llm.nodes.rag_node import RAGNode\n",
    "from morpheus.llm.services.llm_service import LLMService\n",
    "from morpheus.llm.task_handlers.simple_task_handler import SimpleTaskHandler\n",
    "from morpheus.messages import ControlMessage\n",
    "\n",
    "from morpheus.pipeline.linear_pipeline import LinearPipeline\n",
    "from morpheus.service.vdb.faiss_vdb_service import FaissVectorDBService\n",
    "from morpheus.stages.input.in_memory_source_stage import InMemorySourceStage\n",
    "from morpheus.stages.llm.llm_engine_stage import LLMEngineStage\n",
    "from morpheus.stages.output.in_memory_sink_stage import InMemorySinkStage\n",
    "from morpheus.stages.preprocess.deserialize_stage import DeserializeStage\n",
    "from morpheus.utils.concat_df import concat_dataframes\n",
    "\n",
    "def _build_rag_llm_engine(model_config: LLMModelConfig):\n",
    "\n",
    "    engine = LLMEngine()\n",
    "\n",
    "    engine.add_node(\"extracter\", node=ExtracterNode())\n",
    "\n",
    "    prompt = dedent(\"\"\"\n",
    "    You are a helpful assistant. Given the following background information:\n",
    "    {% for c in contexts -%}\n",
    "    Source File: {{ c.metadata.source }}\n",
    "    Source File Language: {{ c.metadata.language }}\n",
    "    Source Content:\n",
    "    ```\n",
    "    {{ c.page_content }}\n",
    "    ```\n",
    "    {% endfor %}\n",
    "\n",
    "    Please answer the following question:\n",
    "    {{ query }}\n",
    "    \"\"\").strip(\"\\n\")\n",
    "\n",
    "    vector_service = FaissVectorDBService(code_faiss_dir, embeddings=embeddings)\n",
    "\n",
    "    vdb_resource = vector_service.load_resource()\n",
    "\n",
    "    llm_service = LLMService.create(model_config.service.type, **model_config.service.model_dump(exclude={\"type\"}))\n",
    "\n",
    "    llm_client = llm_service.get_client(**model_config.model_dump(exclude={\"service\"}))\n",
    "\n",
    "    # Async wrapper around embeddings\n",
    "    async def calc_embeddings(texts: list[str]) -> list[list[float]]:\n",
    "        return embeddings.embed_documents(texts)\n",
    "\n",
    "    engine.add_node(\"rag\",\n",
    "                    inputs=[\"/extracter\"],\n",
    "                    node=RAGNode(prompt=prompt,\n",
    "                                 vdb_service=vdb_resource,\n",
    "                                 embedding=calc_embeddings,\n",
    "                                 llm_client=llm_client))\n",
    "\n",
    "    engine.add_task_handler(inputs=[\"/rag\"], handler=SimpleTaskHandler())\n",
    "\n",
    "    return engine\n",
    "\n",
    "async def run_rag_pipeline(p_config: Config, model_config: LLMModelConfig, question: str):\n",
    "    source_dfs = [\n",
    "        cudf.DataFrame({\"questions\": [question]}),\n",
    "    ]\n",
    "\n",
    "    completion_task = {\"task_type\": \"completion\", \"task_dict\": {\"input_keys\": [\"questions\"], }}\n",
    "\n",
    "    pipe = LinearPipeline(p_config)\n",
    "\n",
    "    pipe.set_source(InMemorySourceStage(p_config, dataframes=source_dfs))\n",
    "\n",
    "    pipe.add_stage(\n",
    "        DeserializeStage(p_config, message_type=ControlMessage, task_type=\"llm_engine\", task_payload=completion_task))\n",
    "\n",
    "    pipe.add_stage(\n",
    "        LLMEngineStage(p_config,\n",
    "                        engine=_build_rag_llm_engine(model_config)))\n",
    "\n",
    "    sink = pipe.add_stage(InMemorySinkStage(p_config))\n",
    "\n",
    "    await pipe.run_async()\n",
    "\n",
    "    messages = sink.get_messages()\n",
    "    responses = concat_dataframes(messages)\n",
    "\n",
    "    # The responses are quite long, when debug is enabled disable the truncation that pandas and cudf normally\n",
    "    # perform on the output\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(\"Response:\\n%s\" % (responses['response'].iloc[0], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = NVFoundationLLMModelConfig.model_validate({\n",
    "    \"service\": {\n",
    "        \"type\": \"nvfoundation\", \"api_key\": None\n",
    "    },\n",
    "    \"model_name\": \"mixtral_8x7b\",\n",
    "    \"temperature\": 0.0\n",
    "})\n",
    "\n",
    "# Run the Pipeline\n",
    "await run_rag_pipeline(pipeline_config, model_config, \"Does the code repo import the `pyarrow_hotfix` package from the `morpheus` root package?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380153a",
   "metadata": {},
   "source": [
    "### RAG Limitations\n",
    "\n",
    "Using the pipeline we built, we can now ask questions about the code in the repository and the LLM will be able use the vector database to answer them. However, what happens if we need to ask questions about the code that are not in the vector database? For example, what if we needed to ask questions about the dependencies that the code uses? Would the LLM be able to answer these questions? Let's try it out by re-running our RAG pipeline with a more complex question:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Pipeline\n",
    "await run_rag_pipeline(pipeline_config, model_config, \"Does the code repo use `langchain` functions which are deprecated?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd8482",
   "metadata": {},
   "source": [
    "It's likely that the model was not able to determine the answer to this question because it would need additional information. Depending on the model used, you might see output similar to:\n",
    "```\n",
    "Based on the provided source code, I cannot determine if the `langchain` functions used in the code are deprecated or not.\n",
    "\n",
    "To determine if `langchain` functions are deprecated, you would need to check the documentation for the specific functions being used in the code or consult the maintainers of the `langchain` package.\n",
    "```\n",
    "\n",
    "How would we go about solving this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d28e86",
   "metadata": {},
   "source": [
    "#### Answering Complex Question with RAG + LLM Agents\n",
    "\n",
    "Intro to LLM Agents and how our checklist + agents approach can help solve multi-step problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b81070",
   "metadata": {},
   "source": [
    "### Running the CVE Pipeline with Morpheus\n",
    "\n",
    "#### The Engine Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628e418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cyber_dev_day.config import EngineConfig\n",
    "\n",
    "# Create the engine configuration\n",
    "engine_config = EngineConfig.model_validate({\n",
    "    'checklist': {\n",
    "        'model': {\n",
    "            'service': {\n",
    "                'type': 'nemo', 'api_key': None, 'org_id': None\n",
    "            },\n",
    "            'model_name': 'gpt-43b-002',\n",
    "            'customization_id': None,\n",
    "            'temperature': 0.0,\n",
    "            'tokens_to_generate': 300\n",
    "        }\n",
    "    },\n",
    "    'agent': {\n",
    "        'model': {\n",
    "            'service': {\n",
    "                'type': 'nvfoundation', 'api_key': None\n",
    "            }, 'model_name': 'mixtral_8x7b', 'temperature': 0.0\n",
    "        },\n",
    "        'sbom': {\n",
    "            'data_file': ''\n",
    "        },\n",
    "        'code_repo': {\n",
    "            'faiss_dir': code_faiss_dir,\n",
    "            'embedding_model_name': \"sentence-transformers/all-mpnet-base-v2\"\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f759e4-fc8c-4c84-ba15-3f3408a2bff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the current configuration object\n",
    "print(engine_config.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b0bf2",
   "metadata": {},
   "source": [
    "#### The Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16bf979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cudf\n",
    "from cyber_dev_day.pipeline_utils import build_cve_llm_engine\n",
    "from morpheus.messages import ControlMessage\n",
    "from morpheus.pipeline.linear_pipeline import LinearPipeline\n",
    "from morpheus.stages.input.in_memory_source_stage import InMemorySourceStage\n",
    "from morpheus.stages.llm.llm_engine_stage import LLMEngineStage\n",
    "from morpheus.stages.output.in_memory_sink_stage import InMemorySinkStage\n",
    "from morpheus.stages.preprocess.deserialize_stage import DeserializeStage\n",
    "from morpheus.utils.concat_df import concat_dataframes\n",
    "\n",
    "async def run_cve_pipeline(p_config: Config, e_config: EngineConfig, input_cves: list[str]):\n",
    "    source_dfs = [\n",
    "        cudf.DataFrame({\n",
    "            \"cve_info\": input_cves\n",
    "        })\n",
    "    ]\n",
    "\n",
    "    completion_task = {\"task_type\": \"completion\", \"task_dict\": {\"input_keys\": [\"cve_info\"], }}\n",
    "\n",
    "    pipe = LinearPipeline(p_config)\n",
    "\n",
    "    pipe.set_source(InMemorySourceStage(p_config, dataframes=source_dfs))\n",
    "\n",
    "    pipe.add_stage(DeserializeStage(p_config, message_type=ControlMessage, task_type=\"llm_engine\", task_payload=completion_task))\n",
    "\n",
    "    pipe.add_stage(LLMEngineStage(p_config, engine=build_cve_llm_engine(e_config)))\n",
    "\n",
    "    sink = pipe.add_stage(InMemorySinkStage(p_config))\n",
    "\n",
    "    await pipe.run_async()\n",
    "\n",
    "    messages = sink.get_messages()\n",
    "    responses = concat_dataframes(messages)\n",
    "\n",
    "    logger.info(\"Pipeline complete\")\n",
    "\n",
    "    print(\"Pipeline complete. Received %s responses:\\n%s\" % (len(messages), responses['response']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ee70c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now run the pipeline with a specified CVE description\n",
    "await run_cve_pipeline(pipeline_config, engine_config, [\n",
    "    \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b8a57",
   "metadata": {},
   "source": [
    "### Hitting the Limits of the LLMs\n",
    "\n",
    "This section will go over some of the areas where LLMs may fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e791c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example to cause the LLM to fail (TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c30da",
   "metadata": {},
   "source": [
    "## Part 3 - Beyond Prototyping\n",
    "\n",
    "This section will focus on refining the prototype to fix any gaps, improve the accuracy, and create a production ready pipeline.\n",
    "\n",
    "### Improving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ef4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for improving the model\n",
    "engine_config_custom_model = engine_config.model_copy(deep=True)\n",
    "\n",
    "# Set the customization ID\n",
    "# engine_config_custom_model.checklist.model.customization_id = \"<CUSTOMIZATION_ID>\"\n",
    "\n",
    "# Run the pipeline\n",
    "await run_cve_pipeline(pipeline_config, engine_config_custom_model, [\n",
    "    \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a826b5",
   "metadata": {},
   "source": [
    "### Batching Multiple Requests\n",
    "\n",
    "This section will show how to run multiple requests simultaneously improving the throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for batching multiple requets\n",
    "await run_cve_pipeline(pipeline_config, engine_config_custom_model, [\n",
    "    \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "] * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66334a9",
   "metadata": {},
   "source": [
    "### Creating a Microservice\n",
    "\n",
    "This section will show how to convert the development pipeline into a microservice which is capable of handling requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for creating a microservice\n",
    "import time\n",
    "import cudf\n",
    "from cyber_dev_day.pipeline_utils import build_cve_llm_engine\n",
    "from morpheus.messages import ControlMessage\n",
    "from morpheus.messages import MessageMeta\n",
    "from morpheus.pipeline.linear_pipeline import LinearPipeline\n",
    "from morpheus.pipeline.stage_decorator import stage\n",
    "from morpheus.stages.input.http_server_source_stage import HttpServerSourceStage\n",
    "from morpheus.stages.input.in_memory_source_stage import InMemorySourceStage\n",
    "from morpheus.stages.llm.llm_engine_stage import LLMEngineStage\n",
    "from morpheus.stages.output.in_memory_sink_stage import InMemorySinkStage\n",
    "from morpheus.stages.preprocess.deserialize_stage import DeserializeStage\n",
    "from morpheus.utils.concat_df import concat_dataframes\n",
    "from morpheus.utils.http_utils import HTTPMethod\n",
    "\n",
    "async def run_cve_pipeline_microservice(p_config: Config, e_config: EngineConfig):\n",
    "\n",
    "    completion_task = {\"task_type\": \"completion\", \"task_dict\": {\"input_keys\": [\"cve_info\"], }}\n",
    "\n",
    "    pipe = LinearPipeline(p_config)\n",
    "\n",
    "    # expected payload is:\n",
    "    # [{\"cve_info\": <sting>},\n",
    "    #  {\"cve_info\": <sting>},]\n",
    "    pipe.set_source(\n",
    "        HttpServerSourceStage(p_config,\n",
    "                                bind_address=\"0.0.0.0\",\n",
    "                                port=26302,\n",
    "                                endpoint=\"/scan\",\n",
    "                                method=HTTPMethod.POST))\n",
    "\n",
    "    @stage\n",
    "    def print_payload(payload: MessageMeta) -> MessageMeta:\n",
    "        serialized_str = payload.df.to_json(orient='records', lines=True)\n",
    "\n",
    "        logger.info(\"======= Got Request =======\\n%s\\n===========================\", serialized_str)\n",
    "\n",
    "        return payload\n",
    "\n",
    "    pipe.add_stage(print_payload(config=p_config))\n",
    "\n",
    "    pipe.add_stage(DeserializeStage(p_config, message_type=ControlMessage, task_type=\"llm_engine\", task_payload=completion_task))\n",
    "\n",
    "    pipe.add_stage(LLMEngineStage(p_config, engine=build_cve_llm_engine(e_config)))\n",
    "\n",
    "    sink = pipe.add_stage(InMemorySinkStage(p_config))\n",
    "\n",
    "    await pipe.run_async()\n",
    "\n",
    "    messages = sink.get_messages()\n",
    "    responses = concat_dataframes(messages)\n",
    "\n",
    "    logger.info(\"Pipeline complete\")\n",
    "\n",
    "    print(\"Pipeline complete. Received %s responses:\\n%s\" % (len(messages), responses['response']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f87ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_cve_pipeline_microservice(pipeline_config, engine_config_custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb51d69",
   "metadata": {},
   "source": [
    "##### Triggering the Microservice\n",
    "\n",
    "To trigger the microservice, we will use a CURL request to send a request to the microservice. Since the notebook cannot run commands while the microservice is running, we need to open up a new terminal to send the request. To do that, follow the steps below:\n",
    "\n",
    "1. In Jupyter Lab, press Ctrl + Shift + L (Shift +  + L on Mac) to open a new Launcher tab\n",
    "2. In the Launcher tab, click on the Terminal icon to open a new terminal\n",
    "3. In the terminal, run the following command to send a request to the microservice:\n",
    "```bash\n",
    "curl --request POST \\\n",
    "  --url http://localhost:26302/scan \\\n",
    "  --header 'Content-Type: application/json' \\\n",
    "  --data '[{\n",
    "      \"cve_info\" : \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "   }]'\n",
    "```\n",
    "4. Once the request is sent, the microservice will process the request and return the results in the terminal\n",
    "   1. To see the results, switch back to the Notebook tab. You should see that the microservice received your request and started processing it.\n",
    "   ```\n",
    "   I20240308 16:00:56.422039 3010283 http_server.cpp:129] Received request: POST : /scan\n",
    "   ```\n",
    "   2. It helps to have the terminal and the notebook side by side so you can see the results in the terminal as they come in. To do this, click on the terminal tab and drag it to the right side of the screen. You should then be able to see the terminal and the notebook side by side similar to the image below:\n",
    "   ![Terminal and Notebook Side by Side](./images/side_by_side.png)\n",
    "5. To stop the microservice, interrupt the kernel by pressing the stop button in the toolbar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
