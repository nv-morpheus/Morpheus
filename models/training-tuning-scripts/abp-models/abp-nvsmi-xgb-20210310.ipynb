{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Anomalous Behaviour Profiling using GPU statistics\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "* Introduction\n",
    "* Dataset\n",
    "* Training\n",
    "* Evaluation\n",
    "* Conclusion\n",
    "* References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "GPUs are used for multiple workloads and often on shared machines. It is important to classify the workloads on GPUs to ensure only allowed activities are taking place. When there is little to no visibility on the application level, one way to do this is to use GPU statistics.\n",
    "\n",
    "We used `nvidia-smi` outputs to make this classification. `nvidia-smi` (The NVIDIA System Management Interface) is a command-line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the management and monitoring of NVIDIA GPU devices. We have collected data during machine learning, deep learning, illegitimate crypto mining workloads were running. \n",
    "\n",
    "In this notebook, we will use data collected during deep learning and crypto mining workloads on a DGX. \n",
    "We will show how to train an XGBoost classification model using RAPIDS that can be saved and used for FIL inference. FIL(Forest Inference Library) is an open-source library in RAPIDS allowing users to accelerate GBDT(Gradient Boosting Decision Tree) and RF(Random Forest) inference with GPUs.\n",
    "For more information on FIL please visit https://docs.rapids.ai/api/cuml/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import cudf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cuml import ForestInference\n",
    "import sklearn.datasets\n",
    "import cupy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/io/json.py:51: UserWarning: Using CPU via Pandas to read JSON dataset, this may be GPU accelerated in the future\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = cudf.read_json(\"../../datasets/training-data/abp-sample-nvsmi-training-data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features we use are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nvidia_smi_log.timestamp',\n",
       " 'nvidia_smi_log.gpu.pci.tx_util',\n",
       " 'nvidia_smi_log.gpu.pci.rx_util',\n",
       " 'nvidia_smi_log.gpu.fb_memory_usage.used',\n",
       " 'nvidia_smi_log.gpu.fb_memory_usage.free',\n",
       " 'nvidia_smi_log.gpu.bar1_memory_usage.total',\n",
       " 'nvidia_smi_log.gpu.bar1_memory_usage.used',\n",
       " 'nvidia_smi_log.gpu.bar1_memory_usage.free',\n",
       " 'nvidia_smi_log.gpu.utilization.gpu_util',\n",
       " 'nvidia_smi_log.gpu.utilization.memory_util',\n",
       " 'nvidia_smi_log.gpu.temperature.gpu_temp',\n",
       " 'nvidia_smi_log.gpu.temperature.gpu_temp_max_threshold',\n",
       " 'nvidia_smi_log.gpu.temperature.gpu_temp_slow_threshold',\n",
       " 'nvidia_smi_log.gpu.temperature.gpu_temp_max_gpu_threshold',\n",
       " 'nvidia_smi_log.gpu.temperature.memory_temp',\n",
       " 'nvidia_smi_log.gpu.temperature.gpu_temp_max_mem_threshold',\n",
       " 'nvidia_smi_log.gpu.power_readings.power_draw',\n",
       " 'nvidia_smi_log.gpu.clocks.graphics_clock',\n",
       " 'nvidia_smi_log.gpu.clocks.sm_clock',\n",
       " 'nvidia_smi_log.gpu.clocks.mem_clock',\n",
       " 'nvidia_smi_log.gpu.clocks.video_clock',\n",
       " 'nvidia_smi_log.gpu.applications_clocks.graphics_clock',\n",
       " 'nvidia_smi_log.gpu.applications_clocks.mem_clock',\n",
       " 'nvidia_smi_log.gpu.default_applications_clocks.graphics_clock',\n",
       " 'nvidia_smi_log.gpu.default_applications_clocks.mem_clock',\n",
       " 'nvidia_smi_log.gpu.max_clocks.graphics_clock',\n",
       " 'nvidia_smi_log.gpu.max_clocks.sm_clock',\n",
       " 'nvidia_smi_log.gpu.max_clocks.mem_clock',\n",
       " 'nvidia_smi_log.gpu.max_clocks.video_clock',\n",
       " 'nvidia_smi_log.gpu.max_customer_boost_clocks.graphics_clock',\n",
       " 'label']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no categorical features in our dataset. `nvidia_smi_log.timestamp` can be used to return the indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows that are collected during mining activities are marked as 1 and the rest are marked as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  80/20 dataset split\n",
    "X_train, X_test, y_train, y_test= train_test_split(df.drop([\"label\",\"nvidia_smi_log.timestamp\"],axis=1), df['label'],  train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move to DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmatrix_train = xgb.DMatrix(X_train, label=y_train)\n",
    "dmatrix_validation = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'tree_method':'gpu_hist','eval_metric': 'auc', 'objective': 'binary:logistic', 'max_depth':5, 'learning_rate':0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on XGBoost parameters can be found [here](https://xgboost.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evallist = [(dmatrix_validation, 'validation'), (dmatrix_train, 'train')]\n",
    "num_round = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:1.00000\ttrain-auc:1.00000\n",
      "[1]\tvalidation-auc:1.00000\ttrain-auc:1.00000\n",
      "[2]\tvalidation-auc:1.00000\ttrain-auc:1.00000\n",
      "[3]\tvalidation-auc:1.00000\ttrain-auc:1.00000\n",
      "[4]\tvalidation-auc:1.00000\ttrain-auc:1.00000\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(params, dmatrix_train, num_round, evallist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model(\"abp-nvsmi-xgb.bst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model & Run inference with FIL(Forest Inference Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier previously saved with xgboost model_save()\n",
    "model_path = \"./abp-nvsmi-xgb.bst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = ForestInference.load(model_path, output_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_preds_gpu = fm.predict(X_test.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = fil_preds_gpu.to_array()\n",
    "y_true = y_test.to_array()\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The model predicted all the workloads in the test set correctly.\n",
    "Since our dataset in this experiment is balanced, we use the accuracy metric.\n",
    "We publish a small sample dataset with this notebook, however, users can use this notebook with `nvidia-smi` outputs from their machines with multiple combinations of different workloads."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
